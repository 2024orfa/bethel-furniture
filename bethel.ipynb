{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = [\n",
    "\"https://bethelfurniture.com\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the headers with a 'User-Agent' to mimic a request from a web browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',\n",
    "}\n",
    "\n",
    "# Make the HTTP GET request with the defined headers\n",
    "r = requests.get(\"https://bethelfurniture.com\", headers=headers)\n",
    "c = r.content\n",
    "\n",
    "# Optionally, you could parse the content using BeautifulSoup for further processing\n",
    "soup = BeautifulSoup(c, 'html.parser')\n",
    "print(soup.prettify())  # Pretty print the parsed HTML content\n",
    "\n",
    "# If you do not need BeautifulSoup and just want the raw content, use this line instead:\n",
    "# print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define headers to mimic a web browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:55.0) Gecko/20100101 Firefox/55.0',\n",
    "}\n",
    "\n",
    "# Make the HTTP GET request with headers\n",
    "response = requests.get(\"https://bethelfurniture.com\", headers=headers)\n",
    "response.raise_for_status()  \n",
    "html_content = response.content\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extract text content from the entire page\n",
    "text_content = soup.get_text(separator=\"\\n\").strip()\n",
    "\n",
    "# Define path to save the extracted content\n",
    "file_path = \"extracted_content.txt\"\n",
    "\n",
    "# Write the extracted text to a file\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(text_content)\n",
    "\n",
    "print(f\"Content successfully scraped and saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Read the extracted content from the text file\n",
    "file_path = \"extracted_content.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "# Initialize the RecursiveCharacterTextSplitter\n",
    "# Adjust `chunk_size` and `chunk_overlap` based on your preference\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=10)\n",
    "\n",
    "# Split the text into chunks\n",
    "chunks = text_splitter.split_text(text_content)\n",
    "\n",
    "# Print the chunks to verify the result\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\\n {chunk}\\n\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the Sentence Transformer model\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Embed the filtered chunks\n",
    "embeddings = model.encode(chunks)\n",
    "\n",
    "# Print each embedding\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    print(f\"Embedding for Chunk {i+1}:\\n{embedding}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lynnmompremier/Desktop/Edwyn/my_env/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# Initialize Pinecone with PineconeClient\n",
    "client = Pinecone(api_key=\"0990c15d-15bf-4dd8-80af-2361a2df1aa3\", environment=\"us-east-1\")\n",
    "# Define the index name\n",
    "index_name = \"bethel\"\n",
    "# Check if the index already exists, if not, create it\n",
    "if index_name not in client.list_indexes().names():\n",
    "    client.create_index(\n",
    "        index_name, \n",
    "        dimension=768, \n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Pinecone with PineconeClient\n",
    "client = Pinecone(api_key=\"0990c15d-15bf-4dd8-80af-2361a2df1aa3\", environment=\"us-east-1\")\n",
    "# Define the index name\n",
    "client.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Connect to the created index\n",
    "index = client.Index(index_name)\n",
    "\n",
    "# Ensure the sentence transformer model is loaded for both indexing and searching\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Prepare and index the data\n",
    "docs = []\n",
    "for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "    doc = {\n",
    "        'id': str(i),\n",
    "        'values': embedding.tolist(),\n",
    "        'metadata': {'text': chunk}\n",
    "    }\n",
    "    docs.append(doc)\n",
    "\n",
    "# Function to split documents into smaller batches\n",
    "def batch_documents(documents, batch_size):\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        yield documents[i:i + batch_size]\n",
    "\n",
    "# Define a batch size\n",
    "batch_size = 100\n",
    "\n",
    "# Upsert the documents to Pinecone in batches\n",
    "for batch in batch_documents(docs, batch_size):\n",
    "    try:\n",
    "        index.upsert(vectors=batch)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during upsert operation for batch: {e}\")\n",
    "\n",
    "print(f\"Successfully indexed {len(docs)} chunks into Pinecone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone vectorstore with the correct embedding function\n",
    "from langchain.vectorstores.pinecone import Pinecone\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableParallel,RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# # Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "pinecone_index_name = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "\n",
    "vectorstore = Pinecone.from_existing_index(\n",
    "    index_name=pinecone_index_name,\n",
    "    embedding=embeddings# Pass the embedding function, not embeddings directly\n",
    ")\n",
    "retriever=vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "template = \"\"\"You are an expert assistant. Use the context provided to answer the user's question accurately.\n",
    "Make sure you review throughly before answering\n",
    "Always answer in a very polite manner no matter the question\n",
    "Make sure to give very deatiled responses when asked a question about price,shipping or discounts\n",
    "Make sure to give deatiled information when asked about reviews\n",
    "If the context does not contain the answer, indicate that the information is not available.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "prompt= ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=openai_api_key,\n",
    "                   model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "chain.invoke(\"How much does Black Modern Bed Pedestal and Headboard 45kgcost?\")\n",
    "#chain.invoke(\"what was the original price of Black Modern Bed Pedestal and Headboard\")\n",
    "#chain.invoke(\"what are the reviews in bethel furniture\")\n",
    "#chain.invoke(\"call us\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
